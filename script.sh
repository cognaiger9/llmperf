python llmperf.py static_batch_throughput --prompt_file input_examples/prompts.txt --iterations 3 --output_tokens 128 vllm --model meta-llama/Llama-2-7b-hf --dtype float16